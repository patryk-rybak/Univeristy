{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "009406d7-6b9a-4d03-9947-7d67f2ac89c6",
    "colab_type": "text",
    "deepnote_cell_height": 90,
    "deepnote_cell_type": "markdown",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/rnoxy/dl_uwr/blob/summer2024/Assignments/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00001-10528e06-f6bc-4d22-87ba-44ee389423e2",
    "deepnote_cell_height": 513.59375,
    "deepnote_cell_type": "markdown",
    "id": "CzR6cZvYkyl6"
   },
   "source": [
    "## Assignment 2\n",
    "\n",
    "**Submission deadlines:** \n",
    "- get at least 4 points by 12.03.2024 (Tue groups)\n",
    "- get at least next 4 points by 19.03.2024 (Tue groups)\n",
    "- remaining points: by 26.03.2024 (Tue groups)\n",
    "\n",
    "**Points:** Aim to get 16 out of 18+ possible points\n",
    "\n",
    "## Submission instructions\n",
    "The class is held on-site in lab rooms. Please prepare you notebook on your computer or anywhere in the cloud (try using DeepNote or Google Colab).\n",
    "\n",
    "Make sure you know all the questions and answers, and that the notebook contains results; before presentation do `Runtime -> Restart and run all`\n",
    "![Picture title](image-20220302-183151.png)\n",
    "\n",
    "We provide starter code, however you are not required to use it as long as you properly solve the tasks.\n",
    "\n",
    "## Extra points\n",
    "\n",
    "You can earn extra 2 points if all your experiments are logged with [Weights and Biases](http://wandb.ai)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00002-c9d8b5e1-13d2-492d-9ad6-d82d4419394b",
    "deepnote_cell_height": 82,
    "deepnote_cell_type": "markdown",
    "id": "eJ7DqCH7NDlC"
   },
   "source": [
    "# Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00003-48229273-726d-45db-bb12-068773ea6b9c",
    "deepnote_cell_height": 433.421875,
    "deepnote_cell_type": "markdown",
    "id": "YXr1RwyMFITD"
   },
   "source": [
    "\n",
    "## Problem 1 [1p]:\n",
    "\n",
    "Let's see why GPUs are useful in deep learning. Compare matrix multiplication speed for a few matrix shapes when implemented:\n",
    "1. as loops in Python\n",
    "2. using np.einsum\n",
    "3. using numpy on CPU\n",
    "4. using pytorch on CPU\n",
    "5. using pytorch on GPU\n",
    "\n",
    "Finally, consider two square matrices, $A$ and $B$. We have 4 possibilities of multiplying them or their transpositions:\n",
    "1. $AB$\n",
    "2. $A^TB$\n",
    "3. $AB^T$\n",
    "4. $A^TB^T$\n",
    "\n",
    "Which option is the fastest? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix shape: (100, 100)\n",
      "Loop-based Python: 0.8200388310006019\n",
      "np.einsum: 0.000482170000395854\n",
      "Numpy on CPU: 0.008281892000013613\n",
      "PyTorch on CPU: 0.05660809800065181\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumpy on CPU:\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_matmul_numpy(A, B))\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch on CPU:\u001b[39m\u001b[38;5;124m\"\u001b[39m, time_matmul_pytorch_cpu(torch\u001b[38;5;241m.\u001b[39mtensor(A), torch\u001b[38;5;241m.\u001b[39mtensor(B)))\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch on GPU:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mtime_matmul_pytorch_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mB\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[8], line 37\u001b[0m, in \u001b[0;36mtime_matmul_pytorch_gpu\u001b[0;34m(A, B)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtime_matmul_pytorch_gpu\u001b[39m(A, B):\n\u001b[1;32m     36\u001b[0m     setup \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimport torch; from __main__ import torch, A, B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtimeit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtorch.matmul(torch.tensor(A).cuda(), torch.tensor(B).cuda())\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/timeit.py:234\u001b[0m, in \u001b[0;36mtimeit\u001b[0;34m(stmt, setup, timer, number, globals)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtimeit\u001b[39m(stmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, setup\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass\u001b[39m\u001b[38;5;124m\"\u001b[39m, timer\u001b[38;5;241m=\u001b[39mdefault_timer,\n\u001b[1;32m    232\u001b[0m            number\u001b[38;5;241m=\u001b[39mdefault_number, \u001b[38;5;28mglobals\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    233\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Convenience function to create Timer object and call timeit method.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTimer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msetup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.10/timeit.py:178\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    176\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<timeit-src>:6\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:302\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    301\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 302\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    306\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import timeit\n",
    "\n",
    "# Define matrix multiplication using loops in Python\n",
    "def matmul_python(A, B):\n",
    "    C = [[0 for _ in range(len(B[0]))] for _ in range(len(A))]\n",
    "    for i in range(len(A)):\n",
    "        for j in range(len(B[0])):\n",
    "            for k in range(len(B)):\n",
    "                C[i][j] += A[i][k] * B[k][j]\n",
    "    return C\n",
    "\n",
    "# Measure time for loop-based matrix multiplication\n",
    "def time_matmul_python(A, B):\n",
    "    setup = \"from __main__ import matmul_python, A, B\"\n",
    "    return timeit.timeit(\"matmul_python(A, B)\", setup=setup, number=1)\n",
    "\n",
    "# Measure time for np.einsum\n",
    "def time_matmul_einsum(A, B):\n",
    "    setup = \"import numpy as np; from __main__ import A, B\"\n",
    "    return timeit.timeit(\"np.einsum('ij,jk->ik', A, B)\", setup=setup, number=1)\n",
    "\n",
    "# Measure time for numpy on CPU\n",
    "def time_matmul_numpy(A, B):\n",
    "    setup = \"import numpy as np; from __main__ import A, B\"\n",
    "    return timeit.timeit(\"np.dot(A, B)\", setup=setup, number=1)\n",
    "\n",
    "# Measure time for PyTorch on CPU\n",
    "def time_matmul_pytorch_cpu(A, B):\n",
    "    setup = \"import torch; from __main__ import torch, A, B\"\n",
    "    return timeit.timeit(\"torch.matmul(torch.tensor(A), torch.tensor(B))\", setup=setup, number=1)\n",
    "\n",
    "# Measure time for PyTorch on GPU\n",
    "def time_matmul_pytorch_gpu(A, B):\n",
    "    setup = \"import torch; from __main__ import torch, A, B\"\n",
    "    return timeit.timeit(\"torch.matmul(torch.tensor(A).cuda(), torch.tensor(B).cuda())\", setup=setup, number=1)\n",
    "\n",
    "\n",
    "\n",
    "# Define shapes for matrix multiplication\n",
    "shapes = [(100, 100), (1000, 1000), (10000, 10000)]\n",
    "\n",
    "# Perform measurements for each shape\n",
    "for shape in shapes:\n",
    "    A = np.random.rand(*shape)\n",
    "    B = np.random.rand(*shape)\n",
    "    print(f\"Matrix shape: {shape}\")\n",
    "    print(\"Loop-based Python:\", time_matmul_python(A, B))\n",
    "    print(\"np.einsum:\", time_matmul_einsum(A, B))\n",
    "    print(\"Numpy on CPU:\", time_matmul_numpy(A, B))\n",
    "    print(\"PyTorch on CPU:\", time_matmul_pytorch_cpu(torch.tensor(A), torch.tensor(B)))\n",
    "    print(\"PyTorch on GPU:\", time_matmul_pytorch_gpu(torch.tensor(A), torch.tensor(B)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00004-6fcf24af-39f5-4e54-a68e-21493b4f3484",
    "deepnote_cell_height": 313.1875,
    "deepnote_cell_type": "markdown",
    "id": "eQa69LGTaiym"
   },
   "source": [
    "## Problem 2: Stochastic Gradient Descent (training MNIST digits) [3p]\n",
    "\n",
    "We provide below starter code that trains a classification model (with softmat + cross entropy loss). Alternatively, implement your own training loop and use it to solve this problem jointly with the next one.\n",
    "\n",
    "Implement the following additions to the SGD code provided:\n",
    "  1. **[1p]** momentum\n",
    "  2. **[1p]** learning rate schedule\n",
    "  3. **[1p]** weight decay, in which we additionally minimize for each weight matrix (but typically not the bias) the sum of its elements squared. One way to implement it is to use the function `model.named_parameters` and select all parameters whose names contain \"`weight`\" rather than \"`bias`\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00005-08ef04aa-9e94-4455-bddc-b843562afd3f",
    "deepnote_cell_height": 350,
    "deepnote_cell_type": "markdown",
    "id": "YsLt4dGsaosv"
   },
   "source": [
    "## Problem 3: Tuning the Network for MNIST [3p]\n",
    "\n",
    "Tune the following network to reach **validation error rate below 1.9%**.\n",
    "This should result in a **test error rate below 2%**. To\n",
    "tune the network you will need to:\n",
    "1. Choose the number of layers (more than 1, less than 5);\n",
    "2. Choose the number of neurons in each layer (more than 100,\n",
    "    less than 5000);\n",
    "3. Pick proper weight initialization;\n",
    "4. Pick proper learning rate schedule (need to decay over time,\n",
    "    a good range to check on MNIST is about 1e-2 ... 1e-1 at the beginning and\n",
    "    half of that after 10000 batches);\n",
    "5. Pick a momentum constant (probably a constant one will be OK).\n",
    "\n",
    "\n",
    "Please note: there are many hyperparameter settings that give the desired answer, some may require tuning all hyperparameters, some only a few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00006-1469d97b-d10e-428a-a29a-f6446ffaa579",
    "deepnote_cell_height": 130.796875,
    "deepnote_cell_type": "markdown",
    "id": "YrUQloaln1UA"
   },
   "source": [
    "## Problem 4: Convolutional Network [2p]\n",
    "\n",
    "Use convolutional and max-pooling layers (`Conv2d`, `Max_pool2d` or their functional variants) and (without dropout) get a test error rate below 1.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00008-b71ece13-36f1-4661-b0c6-3739ba0af279",
    "deepnote_cell_height": 212,
    "deepnote_cell_type": "markdown",
    "id": "mB3T_HuYawyQ"
   },
   "source": [
    "## Problem 5: Data Augmentation [1p]\n",
    "\n",
    "Apply data augmentation methods (e.g. rotations, noise, crops) when training networks on MNIST, to significantly reduce test error rate for your network. You can use functions from the [torchvision.transforms](http://pytorch.org/docs/master/torchvision/transforms.html) module.\n",
    "\n",
    "Please note: when using random transformations during training, make sure they are re-computed in every epoch. Consider applying augmentation either in the training loop or in the `InMemDataLoader`. For the second case, function `InMemDataLoader.__iter__` is a good place to do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 6: Dropout [2p]\n",
    "\n",
    "Learn about dropout:\n",
    "\n",
    "- implement a **dropout** layer \n",
    "- or use `nn.Dropout` (then the exercise is worth 1.5 points)\n",
    "\n",
    "and try to train a\n",
    "network getting below 1.5% test error rates with dropout, but no convolutions, or below 1% when dropout is used jointly with convolutions!\n",
    "\n",
    "Remember to turn off dropout during testing, using `model.train()` and `model.eval()`!\n",
    "\n",
    "Hint: Use [torch.nn.functional.dropout](http://pytorch.org/docs/master/nn.html#torch.nn.functional.dropout).\n",
    "\n",
    "Details: http://arxiv.org/pdf/1207.0580.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00009-9efae45c-dfcb-4687-b7c4-98b007244266",
    "deepnote_cell_height": 226,
    "deepnote_cell_type": "markdown",
    "id": "Af7itFE7a0eY"
   },
   "source": [
    "## Problem 7: Batch Normalization [2p]\n",
    "\n",
    "[Batch Normalization](https://arxiv.org/abs/1502.03167) helps training neural networks because it [normalizes layer activation magnitudes](https://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization.pdf). It typically allows to train networks faster and/or with higher learning rates, lessens the importance\n",
    "of initialization and might eliminate the need for Dropout.\n",
    "\n",
    "Implement Batch Normalization and compare with regular training of MNIST models.\n",
    "\n",
    "Remember to use the batch statistics during model training and to use an average of training batch statistics during model evaluation. For details please consult the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00010-82d7197f-70be-49e8-8a59-99ea637bf693",
    "deepnote_cell_height": 212,
    "deepnote_cell_type": "markdown",
    "id": "CD1Ke8R4a1-Q"
   },
   "source": [
    "## Problem 8: Norm Constraints [1p]\n",
    "\n",
    "Implement norm constraints, i.e. instead of weight decay, that tries to set all weights to small values, apply a limit on the total\n",
    "norm of connections incoming to a neuron. In our case, this\n",
    "corresponds to clipping the norm of *rows* of weight\n",
    "matrices. An easy way of implementing it is to make a gradient\n",
    "step, then look at the norm of rows and scale down those that are\n",
    "over the threshold (this technique is called \"projected gradient descent\").\n",
    "\n",
    "Please consult the Dropout paper (http://arxiv.org/pdf/1207.0580.pdf) for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00012-9ad9a7b8-4ee0-4df2-8a0c-6ed0cb246cdc",
    "deepnote_cell_height": 198,
    "deepnote_cell_type": "markdown",
    "id": "w7LoH9DIa88J"
   },
   "source": [
    "## Problem 9: Hyperparameter tuner [2p]\n",
    "\n",
    "Implement a hyper-parameter tuner able to optimize the learning rate schedule, number of neurons, and similar hyperparameters. To start, use a random search (please see http://jmlr.csail.mit.edu/papers/volume13/bergstra12a/bergstra12a.pdf and especially Fig 1. for intuitions on why random search is better than grid search). It may be a good idea to use a fixed maximum number of epochs (or training time) for each optimization trial to prevent selecting hyperparameters that yield slowly converging solutions. A good result will be a set of hyperparameters that reach on MNIST solutions with test errors less than $1.3\\%$ in no more than 50 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00013-1bb7d06a-33a4-4e1a-9922-d09becbcbddb",
    "deepnote_cell_height": 464.390625,
    "deepnote_cell_type": "markdown",
    "id": "mzJTDu2aE8sk"
   },
   "source": [
    "## Problem 10: Pruning [1p]\n",
    "\n",
    "Prune the MNIST network to retain validation accuracy no worse than 0.1 percentage point at maximum sparsity (maximal number of weights removed from the network).\n",
    "\n",
    "One way to do it is to \n",
    "1. train the network, \n",
    "2. set to zero the smallest weights (typically you can zero up to 50% of weights)\n",
    "3. retrain the network, keeping the zeroed weights zeroed, and repeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00015-f8cf66c4-94bb-492c-abb5-845f0be43678",
    "deepnote_cell_height": 130.796875,
    "deepnote_cell_type": "markdown",
    "id": "aotfN2N2FCM6"
   },
   "source": [
    "## Problem 11: Other tricks [1p-many]\n",
    "\n",
    "The neural network literature is full of tricks for training neural networks. Find some and implement them. Please note: the number of points depends on the hardness of the extension you want to implement. If in doubt, consult the TA beforehand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00016-c2f60d20-e061-443c-a8e3-1713b5192445",
    "deepnote_cell_height": 120.390625,
    "deepnote_cell_type": "markdown",
    "id": "NNfw6pY9sRJe"
   },
   "source": [
    "# Starter code\n",
    "\n",
    "The code below trains a SoftMax regression model in PyTorch. It can easily be extended into a full multilayer neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00017-cf2d5c0e-2979-4394-9d7b-26cf2d6f6225",
    "deepnote_cell_height": 66,
    "deepnote_cell_type": "code",
    "id": "iEUPZksWm9YU"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00018-a007af69-e00b-42a8-8ccd-13a9d5d9f6a5",
    "deepnote_cell_height": 264,
    "deepnote_cell_type": "code",
    "id": "039umgT_lsH2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00019-ef919890-5be1-4bbd-9b4b-3bfb1aefee40",
    "deepnote_cell_height": 732,
    "deepnote_cell_type": "code",
    "id": "tPOMFqLZsfuj"
   },
   "outputs": [],
   "source": [
    "def compute_error_rate(model, data_loader, device=\"cpu\"):\n",
    "    \"\"\"Evaluate model on all samples from the data loader.\n",
    "    \"\"\"\n",
    "    # Put the model in eval mode, and move to the evaluation device.\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    if isinstance(data_loader, InMemDataLoader):\n",
    "        data_loader.to(device)\n",
    "\n",
    "    num_errs = 0.0\n",
    "    num_examples = 0\n",
    "    # we don't need gradient during eval!\n",
    "    with torch.no_grad():\n",
    "        for x, y in data_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            outputs = model.forward(x)\n",
    "            _, predictions = outputs.data.max(dim=1)\n",
    "            num_errs += (predictions != y.data).sum().item()\n",
    "            num_examples += x.size(0)\n",
    "    return num_errs / num_examples\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    \"\"\"Helper to plot the trainig progress over time.\"\"\"\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    train_loss = np.array(history[\"train_losses\"])\n",
    "    plt.semilogy(np.arange(train_loss.shape[0]), train_loss, label=\"batch train loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    train_errs = np.array(history[\"train_errs\"])\n",
    "    plt.plot(np.arange(train_errs.shape[0]), train_errs, label=\"batch train error rate\")\n",
    "    val_errs = np.array(history[\"val_errs\"])\n",
    "    plt.plot(val_errs[:, 0], val_errs[:, 1], label=\"validation error rate\", color=\"r\")\n",
    "    plt.ylim(0, 0.20)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00020-12705b84-2e28-4596-878c-69510f5bf058",
    "deepnote_cell_height": 130.796875,
    "deepnote_cell_type": "markdown",
    "id": "OT6R09JnnYs9"
   },
   "source": [
    "## Data loading\n",
    "\n",
    "Training speed is important. By default, data is loaded on the CPU, then shipped in batches to the GPU. For this exercise, we will load the full dataset onto the GPU, which speeds up training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00021-b3c4901d-b2c9-400d-84d3-667224735d7d",
    "deepnote_cell_height": 1362,
    "deepnote_cell_type": "code",
    "id": "OPh9uR8ZorL7"
   },
   "outputs": [],
   "source": [
    "class InMemDataLoader(object):\n",
    "    \"\"\"\n",
    "    A data loader that keeps all data in CPU or GPU memory.\n",
    "    \"\"\"\n",
    "\n",
    "    __initialized = False\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        sampler=None,\n",
    "        batch_sampler=None,\n",
    "        drop_last=False,\n",
    "    ):\n",
    "        \"\"\"A torch dataloader that fetches data from memory.\"\"\"\n",
    "        batches = []\n",
    "        for i in tqdm(range(len(dataset))):\n",
    "            batch = [torch.tensor(t) for t in dataset[i]]\n",
    "            batches.append(batch)\n",
    "        tensors = [torch.stack(ts) for ts in zip(*batches)]\n",
    "        dataset = torch.utils.data.TensorDataset(*tensors)\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.drop_last = drop_last\n",
    "\n",
    "        if batch_sampler is not None:\n",
    "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
    "                raise ValueError(\n",
    "                    \"batch_sampler option is mutually exclusive \"\n",
    "                    \"with batch_size, shuffle, sampler, and \"\n",
    "                    \"drop_last\"\n",
    "                )\n",
    "            self.batch_size = None\n",
    "            self.drop_last = None\n",
    "\n",
    "        if sampler is not None and shuffle:\n",
    "            raise ValueError(\"sampler option is mutually exclusive with \" \"shuffle\")\n",
    "\n",
    "        if batch_sampler is None:\n",
    "            if sampler is None:\n",
    "                if shuffle:\n",
    "                    sampler = torch.utils.data.RandomSampler(dataset)\n",
    "                else:\n",
    "                    sampler = torch.utils.data.SequentialSampler(dataset)\n",
    "            batch_sampler = torch.utils.data.BatchSampler(\n",
    "                sampler, batch_size, drop_last\n",
    "            )\n",
    "\n",
    "        self.sampler = sampler\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.__initialized = True\n",
    "\n",
    "    def __setattr__(self, attr, val):\n",
    "        if self.__initialized and attr in (\"batch_size\", \"sampler\", \"drop_last\"):\n",
    "            raise ValueError(\n",
    "                \"{} attribute should not be set after {} is \"\n",
    "                \"initialized\".format(attr, self.__class__.__name__)\n",
    "            )\n",
    "\n",
    "        super(InMemDataLoader, self).__setattr__(attr, val)\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch_indices in self.batch_sampler:\n",
    "            yield self.dataset[batch_indices]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)\n",
    "\n",
    "    def to(self, device):\n",
    "        self.dataset.tensors = tuple(t.to(device) for t in self.dataset.tensors)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00022-781fa74f-113b-42aa-abad-f98814527964",
    "deepnote_cell_height": 390,
    "deepnote_cell_type": "code",
    "id": "d4RuDI9YpPhe"
   },
   "source": [
    "```python\n",
    "# Monkey-patch MNIST to use a more robust MNIST mirror\n",
    "torchvision.datasets.MNIST.resources = [\n",
    "    (\n",
    "        \"https://web.archive.org/web/20150906081542/http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\",\n",
    "        \"f68b3c2dcbeaaa9fbdd348bbdeb94873\",\n",
    "    ),\n",
    "    (\n",
    "        \"https://web.archive.org/web/20150906081542/http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\",\n",
    "        \"d53e105ee54ea40749a09fcbcd1e9432\",\n",
    "    ),\n",
    "    (\n",
    "        \"https://web.archive.org/web/20150906081542/http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\",\n",
    "        \"9fb629c4189551a2d022fa330f9573f3\",\n",
    "    ),\n",
    "    (\n",
    "        \"https://web.archive.org/web/20150906081542/http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\",\n",
    "        \"ec29112dd5afa0611ce80d1b7f02629c\",\n",
    "    ),\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00023-1ae08eac-ed89-46d5-b212-29029275d401",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 220,
     "referenced_widgets": [
      "f812ea5e8de34f13b6d77523bd59619b",
      "27d7e1ef4252482ebd054155383ef73c",
      "cd6c38cfe20a453b9890b91e379f6adb",
      "f9ab073ef44d4d1190e6c16897effe36",
      "89d18bcff5b4416fa2ebf7ecf5e576bf",
      "7064e43a34b945dca49470e1eb118469",
      "32b37b209d61481e8a5dd656f639f221",
      "52d8ab18c3f34643aa1f07add6180714",
      "fd0c0b007c854d00a4432f5d5004b70f",
      "beca25b53ebe467caa02205b094b19a1",
      "6105dc20b88c4508958c9b0baa459b23",
      "fc2532f430c74268a8541613b1acc2df",
      "817a42f342eb4d02ba2072ad90d7c5bb",
      "98fe0324eeb346a6ad37ffc8ba75d58d",
      "b53524197a3d401ead0a99318bd6ec0c",
      "286f1846c16f4d988222e0d7d7f2a05a",
      "ffa6fe99547c487397510794b8ddd192",
      "a3eb493e14334d2c8812c6b23013948a",
      "b624c5832e76473285cc4ceb5b964be2",
      "f6f9b7644453421cb44cb7323a30a372",
      "845e278821bf42f89d3d84df8e297aee",
      "6e8b5b619d114e28a67232b9754c9d67",
      "04cf131f657340efb0b4e19fe2e3e049",
      "33639dd21074403c821b7025f337aaf2"
     ]
    },
    "deepnote_cell_height": 1054.796875,
    "deepnote_cell_type": "code",
    "id": "wDM2KTPQm8V3",
    "outputId": "e92434b9-18e4-4396-efad-3080a73bdbb9"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "batch_size = 128\n",
    "data_path = \"./data\"\n",
    "\n",
    "transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "_test = torchvision.datasets.MNIST(\n",
    "    data_path, train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Load training data, split into train and valid sets\n",
    "_train = torchvision.datasets.MNIST(\n",
    "    data_path, train=True, download=True, transform=transform\n",
    ")\n",
    "_train.data = _train.data[:50000]\n",
    "_train.targets = _train.targets[:50000]\n",
    "\n",
    "_valid = torchvision.datasets.MNIST(\n",
    "    data_path, train=True, download=True, transform=transform\n",
    ")\n",
    "_valid.data = _valid.data[50000:]\n",
    "_valid.targets = _valid.targets[50000:]\n",
    "\n",
    "mnist_loaders = {\n",
    "    \"train\": InMemDataLoader(_train, batch_size=batch_size, shuffle=True),\n",
    "    \"valid\": InMemDataLoader(_valid, batch_size=batch_size, shuffle=False),\n",
    "    \"test\": InMemDataLoader(_test, batch_size=batch_size, shuffle=False),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "00024-481f7a8f-3abb-4f8f-aaba-951e8e06aafc",
    "deepnote_cell_height": 108.390625,
    "deepnote_cell_type": "markdown",
    "id": "rRYr7XmnnGO_"
   },
   "source": [
    "## SGD implementation\n",
    "\n",
    "We provide below a scaffolding for SGD. You will need to fill the TODOs while solving the assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00025-2145e55b-7562-438c-bce3-8720962f9bfb",
    "deepnote_cell_height": 2460,
    "deepnote_cell_type": "code",
    "id": "WY1xG-cqnRoE"
   },
   "outputs": [],
   "source": [
    "def SGD(\n",
    "    model,\n",
    "    data_loaders,\n",
    "    alpha=1e-4,\n",
    "    epsilon=0.0,\n",
    "    decay=0.0,\n",
    "    num_epochs=1,\n",
    "    max_num_epochs=np.nan,\n",
    "    patience_expansion=1.5,\n",
    "    log_every=100,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "\n",
    "    # Put the model in train mode, and move to the evaluation device.\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for data_loader in data_loaders.values():\n",
    "        if isinstance(data_loader, InMemDataLoader):\n",
    "            data_loader.to(device)\n",
    "\n",
    "    #\n",
    "    # TODO for Problem 2.3: Initialize momentum variables\n",
    "    # Hint: You need one velocity matrix for each parameter\n",
    "    #\n",
    "    velocities = [None for _ in model.parameters()]\n",
    "    #\n",
    "    iter_ = 0\n",
    "    epoch = 0\n",
    "    best_params = None\n",
    "    best_val_err = np.inf\n",
    "    history = {\"train_losses\": [], \"train_errs\": [], \"val_errs\": []}\n",
    "    print(\"Training the model!\")\n",
    "    print(\"Interrupt at any time to evaluate the best validation model so far.\")\n",
    "    try:\n",
    "        tstart = time.time()\n",
    "        siter = iter_\n",
    "        while epoch < num_epochs:\n",
    "            model.train()\n",
    "            epoch += 1\n",
    "            if epoch > max_num_epochs:\n",
    "                break\n",
    "            #\n",
    "            # TODO: You can implement learning rate control here (it is updated\n",
    "            # once per epoch), or below in the loop over minibatches.\n",
    "            #\n",
    "            \n",
    "            for x, y in data_loaders[\"train\"]:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                iter_ += 1\n",
    "                # This calls the `forward` function: https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_module.html\n",
    "                out = model(x)\n",
    "                loss = model.loss(out, y)\n",
    "                loss.backward()\n",
    "                _, predictions = out.max(dim=1)\n",
    "                batch_err_rate = (predictions != y).sum().item() / out.size(0)\n",
    "\n",
    "                history[\"train_losses\"].append(loss.item())\n",
    "                history[\"train_errs\"].append(batch_err_rate)\n",
    "\n",
    "                # disable gradient computations - we do not want torch to\n",
    "                # backpropagate through the gradient application!\n",
    "                with torch.no_grad():\n",
    "                    for (name, p), v in zip(model.named_parameters(), velocities):\n",
    "                        if \"weight\" in name:\n",
    "                            #\n",
    "                            # TODO for Problem 2.3: Implement weight decay (L2 regularization\n",
    "                            # on weights by changing the gradients\n",
    "                            # p.grad += TODO\n",
    "                            #\n",
    "                            pass\n",
    "\n",
    "                        #\n",
    "                        # TODO for Problem 2.2: Implement a learning rate schedule\n",
    "                        # Hint: You can use the iteration or epoch counters\n",
    "                        # alpha = TODO\n",
    "                        #\n",
    "\n",
    "                        #\n",
    "                        # TODO for Problem 2.1: If needed, implement here a momentum schedule\n",
    "                        # epsilon = TODO\n",
    "                        #\n",
    "\n",
    "                        #\n",
    "                        # TODO for Problem 2.1: Implement velocity updates for momentum\n",
    "                        # lease make sure to modify the contents of v, not the v pointer!!!\n",
    "                        #\n",
    "                        # v[...] = TODO\n",
    "\n",
    "                        #\n",
    "                        # TODO for Problem 2: Set a more sensible learning rule here,\n",
    "                        #       using your learning rate schedule and momentum\n",
    "                        #\n",
    "                        p -= alpha * p.grad\n",
    "\n",
    "                        # Zero gradients for the next iteration\n",
    "                        p.grad.zero_()\n",
    "\n",
    "                if iter_ % log_every == 0:\n",
    "                    num_iter = iter_ - siter + 1\n",
    "                    print(\n",
    "                        \"Minibatch {0: >6}  | loss {1: >5.2f} | err rate {2: >5.2f}%, steps/s {3: >5.2f}\".format(\n",
    "                            iter_,\n",
    "                            loss.item(),\n",
    "                            batch_err_rate * 100.0,\n",
    "                            num_iter / (time.time() - tstart),\n",
    "                        )\n",
    "                    )\n",
    "                    tstart = time.time()\n",
    "\n",
    "            val_err_rate = compute_error_rate(model, data_loaders[\"valid\"], device)\n",
    "            history[\"val_errs\"].append((iter_, val_err_rate))\n",
    "\n",
    "            if val_err_rate < best_val_err:\n",
    "                # Adjust num of epochs\n",
    "                num_epochs = int(np.maximum(num_epochs, epoch * patience_expansion + 1))\n",
    "                best_epoch = epoch\n",
    "                best_val_err = val_err_rate\n",
    "                best_params = [p.detach().cpu() for p in model.parameters()]\n",
    "            clear_output(True)\n",
    "            m = \"After epoch {0: >2} | valid err rate: {1: >5.2f}% | doing {2: >3} epochs\".format(\n",
    "                epoch, val_err_rate * 100.0, num_epochs\n",
    "            )\n",
    "            print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "\n",
    "    if best_params is not None:\n",
    "        print(\"\\nLoading best params on validation set (epoch %d)\\n\" % (best_epoch))\n",
    "        with torch.no_grad():\n",
    "            for param, best_param in zip(model.parameters(), best_params):\n",
    "                param[...] = best_param\n",
    "    plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "00026-06863917-ddb1-425f-9d6e-93c06b30e87b",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "deepnote_cell_height": 1464.5625,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     null,
     249.5,
     251.078125
    ],
    "id": "2gmDmR2K6CVQ",
    "outputId": "4744390f-6966-4514-bf06-6940d6c1b336"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(Model, self).__init__()\n",
    "        self.layers = nn.Sequential(*args, **kwargs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X.view(X.size(0), -1)\n",
    "        return self.layers.forward(X)\n",
    "\n",
    "    def loss(self, Out, Targets):\n",
    "        return F.cross_entropy(Out, Targets)\n",
    "\n",
    "\n",
    "model = Model(nn.Linear(28 * 28, 10))\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Initialize parameters\n",
    "    for name, p in model.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            p.normal_(0, 0.5)\n",
    "        elif \"bias\" in name:\n",
    "            p.zero_()\n",
    "        else:\n",
    "            raise ValueError('Unknown parameter name \"%s\"' % name)\n",
    "\n",
    "# On GPU enabled devices set device='cuda' else set device='cpu'\n",
    "t_start = time.time()\n",
    "SGD(model, mnist_loaders, alpha=1e-1, max_num_epochs=30, device=\"cuda\")\n",
    "\n",
    "\n",
    "test_err_rate = compute_error_rate(model, mnist_loaders[\"test\"])\n",
    "m = (\n",
    "    f\"Test error rate: {test_err_rate * 100.0:.3f}%, \"\n",
    "    f\"training took {time.time() - t_start:.0f}s.\"\n",
    ")\n",
    "print(\"{0}\\n{1}\\n{0}\".format(\"-\" * len(m), m))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Assignment2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "ffaf5b3e-ad2e-45f4-b61f-77edfc82388b",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "04cf131f657340efb0b4e19fe2e3e049": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "27d7e1ef4252482ebd054155383ef73c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "286f1846c16f4d988222e0d7d7f2a05a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32b37b209d61481e8a5dd656f639f221": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "33639dd21074403c821b7025f337aaf2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "52d8ab18c3f34643aa1f07add6180714": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6105dc20b88c4508958c9b0baa459b23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98fe0324eeb346a6ad37ffc8ba75d58d",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_817a42f342eb4d02ba2072ad90d7c5bb",
      "value": 10000
     }
    },
    "6e8b5b619d114e28a67232b9754c9d67": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7064e43a34b945dca49470e1eb118469": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "817a42f342eb4d02ba2072ad90d7c5bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "845e278821bf42f89d3d84df8e297aee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "89d18bcff5b4416fa2ebf7ecf5e576bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "98fe0324eeb346a6ad37ffc8ba75d58d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3eb493e14334d2c8812c6b23013948a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b53524197a3d401ead0a99318bd6ec0c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b624c5832e76473285cc4ceb5b964be2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e8b5b619d114e28a67232b9754c9d67",
      "max": 10000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_845e278821bf42f89d3d84df8e297aee",
      "value": 10000
     }
    },
    "beca25b53ebe467caa02205b094b19a1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd6c38cfe20a453b9890b91e379f6adb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7064e43a34b945dca49470e1eb118469",
      "max": 50000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89d18bcff5b4416fa2ebf7ecf5e576bf",
      "value": 50000
     }
    },
    "f6f9b7644453421cb44cb7323a30a372": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_33639dd21074403c821b7025f337aaf2",
      "placeholder": "",
      "style": "IPY_MODEL_04cf131f657340efb0b4e19fe2e3e049",
      "value": " 10000/10000 [02:08&lt;00:00, 77.73it/s]"
     }
    },
    "f812ea5e8de34f13b6d77523bd59619b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_cd6c38cfe20a453b9890b91e379f6adb",
       "IPY_MODEL_f9ab073ef44d4d1190e6c16897effe36"
      ],
      "layout": "IPY_MODEL_27d7e1ef4252482ebd054155383ef73c"
     }
    },
    "f9ab073ef44d4d1190e6c16897effe36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52d8ab18c3f34643aa1f07add6180714",
      "placeholder": "",
      "style": "IPY_MODEL_32b37b209d61481e8a5dd656f639f221",
      "value": " 50000/50000 [00:08&lt;00:00, 5595.16it/s]"
     }
    },
    "fc2532f430c74268a8541613b1acc2df": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_286f1846c16f4d988222e0d7d7f2a05a",
      "placeholder": "",
      "style": "IPY_MODEL_b53524197a3d401ead0a99318bd6ec0c",
      "value": " 10000/10000 [02:10&lt;00:00, 76.82it/s]"
     }
    },
    "fd0c0b007c854d00a4432f5d5004b70f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6105dc20b88c4508958c9b0baa459b23",
       "IPY_MODEL_fc2532f430c74268a8541613b1acc2df"
      ],
      "layout": "IPY_MODEL_beca25b53ebe467caa02205b094b19a1"
     }
    },
    "ffa6fe99547c487397510794b8ddd192": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b624c5832e76473285cc4ceb5b964be2",
       "IPY_MODEL_f6f9b7644453421cb44cb7323a30a372"
      ],
      "layout": "IPY_MODEL_a3eb493e14334d2c8812c6b23013948a"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
